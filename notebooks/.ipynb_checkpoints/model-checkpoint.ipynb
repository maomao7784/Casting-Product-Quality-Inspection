{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "\n",
    "# Define utility functions\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# Data Preprocessor\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, input_dir, output_dir, size=(256, 256)):\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.size = size\n",
    "        create_dir(self.output_dir)\n",
    "\n",
    "    def preprocess_image(self, image_path, output_path):\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error: Unable to read image {image_path}\")\n",
    "            return\n",
    "        image = cv2.resize(image, self.size)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imwrite(output_path, image)\n",
    "        print(f\"Processed {output_path}\")\n",
    "\n",
    "    def preprocess(self):\n",
    "        for subdir, _, files in os.walk(self.input_dir):\n",
    "            for file in files:\n",
    "                input_path = os.path.join(subdir, file)\n",
    "                output_subdir = subdir.replace(self.input_dir, self.output_dir)\n",
    "                create_dir(output_subdir)\n",
    "                output_path = os.path.join(output_subdir, file)\n",
    "                self.preprocess_image(input_path, output_path)\n",
    "\n",
    "# Data Augmentor\n",
    "class DataAugmentor:\n",
    "    def __init__(self, input_dir, output_dir, augmentations, num_samples=1000):\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.augmentations = transforms.Compose(augmentations)\n",
    "        self.num_samples = num_samples\n",
    "        create_dir(self.output_dir)\n",
    "\n",
    "    def augment_data(self):\n",
    "        for class_dir in ['def_front', 'ok_front']:\n",
    "            class_input_dir = os.path.join(self.input_dir, class_dir)\n",
    "            class_output_dir = os.path.join(self.output_dir, class_dir)\n",
    "            create_dir(class_output_dir)\n",
    "            images = [f for f in os.listdir(class_input_dir) if os.path.isfile(os.path.join(class_input_dir, f))]\n",
    "            \n",
    "            if len(images) == 0:\n",
    "                print(f\"No images found in {class_input_dir}\")\n",
    "                continue\n",
    "            \n",
    "            for i in range(self.num_samples):\n",
    "                img_name = images[i % len(images)]\n",
    "                image = Image.open(os.path.join(class_input_dir, img_name))\n",
    "                augmented_image = self.augmentations(image)\n",
    "                augmented_image.save(os.path.join(class_output_dir, f\"augmented_{i}_{img_name}\"))\n",
    "                print(f\"Saved augmented image: {os.path.join(class_output_dir, f'augmented_{i}_{img_name}')}\")\n",
    "\n",
    "# Dataset class\n",
    "class MedicalImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.classes = ['def_front', 'ok_front']\n",
    "        self.transform = transform if transform else transforms.ToTensor()\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label, class_dir in enumerate(self.classes):\n",
    "            class_path = os.path.join(self.image_dir, class_dir)\n",
    "            for image_name in os.listdir(class_path):\n",
    "                self.image_paths.append(os.path.join(class_path, image_name))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Load image paths and labels\n",
    "def load_image_paths_and_labels(image_dir):\n",
    "    classes = ['def_front', 'ok_front']\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for label, class_dir in enumerate(classes):\n",
    "        class_path = os.path.join(image_dir, class_dir)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_paths.append(os.path.join(class_path, image_name))\n",
    "            labels.append(label)\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "# CNN Model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Training and evaluation functions\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, '\n",
    "              f'Train Loss: {epoch_loss:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_loss /= len(dataloader.dataset)\n",
    "    val_acc = correct / total\n",
    "    return val_loss, val_acc\n",
    "\n",
    "# Configuration class\n",
    "class Config:\n",
    "    RAW_DATA_DIR = '../data/casting_data'\n",
    "    PROCESSED_DATA_DIR = '../data/processed_data'\n",
    "    AUGMENTED_DATA_DIR = '../data/augmentation'\n",
    "    MODEL_PATH = 'models/trained_models/model.pth'\n",
    "    BATCH_SIZE = 32\n",
    "    LEARNING_RATE = 0.001\n",
    "    NUM_EPOCHS = 25\n",
    "    IMAGE_SIZE = (256, 256)\n",
    "\n",
    "    @staticmethod\n",
    "    def train_transforms():\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize(Config.IMAGE_SIZE),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    @staticmethod\n",
    "    def test_transforms():\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize(Config.IMAGE_SIZE),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "# Main script\n",
    "if __name__ == '__main__':\n",
    "    # Preprocess data\n",
    "    base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    train_input_dir = os.path.join(base_dir, Config.RAW_DATA_DIR, 'train')\n",
    "    train_output_dir = os.path.join(base_dir, Config.PROCESSED_DATA_DIR, 'train')\n",
    "    test_input_dir = os.path.join(base_dir, Config.RAW_DATA_DIR, 'test')\n",
    "    test_output_dir = os.path.join(base_dir, Config.PROCESSED_DATA_DIR, 'test')\n",
    "\n",
    "    preprocessor = DataPreprocessor(train_input_dir, train_output_dir)\n",
    "    preprocessor.preprocess()\n",
    "\n",
    "    preprocessor = DataPreprocessor(test_input_dir, test_output_dir)\n",
    "    preprocessor.preprocess()\n",
    "\n",
    "    # Augment data\n",
    "    augmentations = [\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop(Config.IMAGE_SIZE[0], scale=(0.8, 1.0)),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n",
    "    ]\n",
    "    \n",
    "    train_input_dir = os.path.join(base_dir, Config.PROCESSED_DATA_DIR, 'train')\n",
    "    train_output_dir = os.path.join(base_dir, Config.AUGMENTED_DATA_DIR, 'train')\n",
    "    test_input_dir = os.path.join(base_dir, Config.PROCESSED_DATA_DIR, 'test')\n",
    "    test_output_dir = os.path.join(base_dir, Config.AUGMENTED_DATA_DIR, 'test')\n",
    "\n",
    "    augmentor = DataAugmentor(train_input_dir, train_output_dir, augmentations)\n",
    "    augmentor.augment_data()\n",
    "\n",
    "    augmentor = DataAugmentor(test_input_dir, test_output_dir, augmentations)\n",
    "    augmentor.augment_data()\n",
    "\n",
    "    # Load dataset\n",
    "    config = Config()\n",
    "    image_paths, labels = load_image_paths_and_labels(os.path.join(base_dir, Config.PROCESSED_DATA_DIR, 'train'))\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_dataset = MedicalImageDataset(train_paths, train_labels, transform=config.train_transforms())\n",
    "    val_dataset = MedicalImageDataset(val_paths, val_labels, transform=config.test_transforms())\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = CNNModel(num_classes=2)\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Train model\n",
    "    train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=config.NUM_EPOCHS, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
